# 线性回归（linear regression）     

线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w'x+e，e为误差服从均值为0的正态分布。 

回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。


$$
f(x) = \int_{-\infty}^\infty f(\xi)\,e^{2 \pi \xi x} \,d\xi
$$

$$
a = b + 2
$$





当我们只用一个x来预测y，就是一元线性回归，也就是在找一个直线来拟合数据。比如，我有一组数据画出来的散点图，横坐标代表广告投入金额，纵坐标代表销售量，线性回归就是要找一条直线，并且让这条直线尽可能地拟合图中的数据点。 




回归算法是相对分类算法而言的，与我们想要预测的目标变量y的值类型有关。
如果目标变量y是分类型变量，如预测用户的性别（男、女），预测月季花的颜色（红、白、黄……），预测是否患有肺癌（是、否），那我们就需要用分类算法去拟合训练数据并做出预测；
如果y是连续型变量，如预测用户的收入（4千，2万，10万……），预测员工的通勤距离（500m，1km，2万里……），预测患肺癌的概率（1%，50%，99%……），我们则需要用回归模型。

聪明的你一定会发现，有时分类问题也可以转化为回归问题，例如刚刚举例的肺癌预测，我们可以用回归模型先预测出患肺癌的概率，然后再给定一个阈值，例如50%，概率值在50%以下的人划为没有肺癌，50%以上则认为患有肺癌。

这种分类型问题的回归算法预测，最常用的就是逻辑回归，后面我们会讲到