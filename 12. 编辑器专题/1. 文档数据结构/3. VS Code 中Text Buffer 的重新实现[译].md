# VS Code 中的 Text Buffer 的重新实现 [译]

原文标题： Text Buffer Reimplementation
原文链接： https://code.visualstudio.com/blogs/2018/03/23/text-buffer-reimplementation
原文作者： Peng Lyu ( VS Code Team member)  

正文开始

在 VS Code 的 1.21 发布版本中包含了一项重大改进：全新的 text buffer 实现，在内存和速度方面都有大幅的性能提升。在这篇文章里，我会告诉大家：我们是如何选择和设计数据结构和算法，从而达成这些改进的。

在关于 javascript 程序的性能讨论中，经常会有一种声音：建议使用 native code 实现。针对 VS Code 的 text buffer 问题，这些讨论早在一年多以前就开始了。 在经历深度探索之后，我们发现用 c++ 实现 text buffer 的确会使内存大幅度下降，但是并没有得到我们期望的性能提升。在 native 和 V8 引擎之间字符串转换非常消耗性能，消耗了通过 c++ 实现带来的性能优势。 在文章的末尾，我们会详细讨论这个问题。    

既然不能采用 native 的方式，所以我们必须找到方法来优化 javasript/typescript 代码。有一些非常有启发性的文章在讲如何优化 js， 例如 Vyacheslav Egorov 的这篇文章里[Maybe you don't need Rust and WASM to speed up your JS](https://mrale.ph/blog/2018/02/03/maybe-you-dont-need-rust-to-speed-up-your-js.html)，展示了如何把 javascript 引擎推到极限，从而榨取尽可能多的性能。即使不使用这些偏底层的引擎优化技巧，通过使用更合适的数据结构和更快的算法来把速度提升一个或几个数量级，仍然是可能的。  


# 之前的 text buffer 数据结构
编辑器的核心模型是基于文本行的，例如，开发者是一行一行地读写代码，编译器提供的运行时诊断/堆栈追踪提供了行数和列数，tokenization 引擎是一行一行地运行，等等。虽然简单，我们希望通过 text buffer 的实现来增强 VS Code 的想法， 从我们第一天启动 Monaco Editor 项目时就没有变过。 开始的时候，我们使用的是以行为单位的数组的方法，并且运行良好，因为常规的文本输入都相对较小。当用户正在输入时，我们在数组中定位到用户正在输入的行，并且修改这一行的字符串进行替换；当用户插入新的一行时，我们在行数组( line array) 中插入一个新的行对象，由 JS 引擎帮我们完成繁重的底层内存操作。

但是，我们在不断地收到 VS Code 的崩溃反馈：当打开某些文件的时候会导致内存不足。例如，用户打开一个 35 MB 的文件失败。问题原因在于，这个文件里有太多的行，1370万行。我们之前为每一行创建了一个 ModelLine 对象，每个对象大概占用了 40 - 60 字节，所以 line array 使用了大约 600 MB 的内存来存放文档。这个内存大小是文件原始大小的 20 倍。  

line array 表示方法的另外一个问题就是打开一个文件的速度。 为了构建 line array，我必须把内容按行进行拆分，每一行一个字符串对象。这个拆分行为消耗大量性能，你会在下面的基准测试（benchmark） 中看到这一点。


# 新的 text buffer 实现
line array 表示方法占用了大量内存，并且在构建的时候非常耗时，但它的好处是能够快速进行行查找。理想的情况下，我们希望只存储文件的文本，没有额外的 metadata。 所以，我们开始寻找一种数据结构，占用尽可能少的 metadata。在评估完一些数据结构以后，我发现 piece table 可能是一个很好的备选项。     

## 使用 piece table 来避免过多的 meta-data
Piece Table 是一种用于表示文本文档中一系列编辑的数据结构：
```ts
class PieceTable {
  original: string; // original contents
  added: string; // user added contents
  nodes: Node[];
}

class Node {
  type: NodeType;
  start: number;
  length: number;
}

enum NodeType {
  Original,
  Added
}
```
在文件加载完之后，piece table 将整个文件内容存储在 `original` field 中， 这个时候 `added` field 是空的, table 里只有一个类型为`NodeType.Original`的 Node。 当用户在文件尾部输入时，我们将新增加的内容添加到 `added` field, 并且在 node list 中插入一个类型为 `NodeType.Added` 的 Node。类似地，如果用户是在文件中间输入时，我们将原来的 Node 进行拆分，并且根据需要插入一个新的 Node。

下面的动画展示了如何在 piece table 中以一行一行的方式访问文档行。它有两个 buffer (original 和 added), 三个 Node（在原来的内容中间插入了一段文字）。

[插图1](traditional-piece-table.gif)

piece table 的初始内存大小，十分接近原始文件的大小，编辑动作需要的内容正比于编辑动作的数量和新增文本的大小。所以，一般来说，piece table 在内存方面具有巨大的优势。 但是，低内存的代价就是，访问一个行（真实的行）的速度慢。例如，如果你想要得到第 1000 行的内容，唯一的办法是从文档的开始的每一个字符开始遍历，从第 999 个换行符开始，读取字符，直到下一个换行符号。  


## 使用 caching 进行更快的行查找
传统的 piece table 的 nodes 中只包含了偏移量，但是我们可以在里面添加换行信息，从而可以更快的行查找。直观的方法就是，在 node 节点的文本中找到每一个换行符的 offset，并且存储起来。 
```ts
class PieceTable {
  original: string;
  added: string;
  nodes: Node[];
}

class Node {
  type: NodeType;
  start: number;
  length: number;
  lineStarts: number[];   // 存储换行符的 offset
}

enum NodeType {
  Original,
  Added
}
```
例如，如果你想从一个给定的 Node 中找到第二行，你可以从 `node.lineStarts[0]` and `node.lineStarts[1]` 的相对偏移量中读取到这一行的文本的位置。因为我们直到一个 Node 中有多少个换行，所以访问一个文档中随机行变得很直接：从第一个 Node （而不是之前的字符）开始读取，直到找到目标点的换行符。

这个算法仍然很简单，但是相比之前，已经很好了，我们可以直接跳过文本中的 chunk，而不是之前的一个字符一个字符的查找。我们会在下面讨论，如何可以做的更好。    

## 避免字符串拼接陷阱

piece table 包含有个两个 buffer，一个用于存放是原始文件内容，另外一个用于存放用户编辑。 在 VS Code 中，我们通过 node.js 的 fs.readFile 来以 64KB 的 chunks 来加载文件。 所以，当文件很大时，例如 64MB，我们会得到 1000 个 chunks。 在收到所有的 chunks 以后，我们把它们拼接为一个巨大的字符串，存放到 piece table 的 original buffer 中。  

这看起来是可行合理的，但是事实上，V8 引擎会无情打你的脸。我尝试过打开一个 500 MB 的文件 但是得到了一个异常，因为在我使用的 V8 引擎的版本中，字符串的最大长度是 256 MB。 这个限制会在 V8 引擎的未来版本中提高到 1 GB，但是并不是从根本上解决问题。    


相比原来的 piece table 中只有两个 buffer （original buffer 和 added buffer） 而言， 我们改成了 buffers list， 尽量保证这个 list 不能过长，通过 fs.readFile 的时候避免字符串拼接。 每次收到 64KB 的 chunk，我们会把它放进 buffer list 中，并且创建一个 Node 指向这个 buffer。  
```ts
class PieceTable {
  buffers: string[];      // buffer list
  nodes: Node[];
}

class Node {
  bufferIndex: number;      // buffer index
  start: number; // start offset in buffers[bufferIndex]
  length: number;
  lineStarts: number[];
}
```

## 使用平衡二叉树(红黑树)来加速行查找

不使用字符串拼接的方法的情况下，我们现在打开大文件，可能会产生潜在的性能问题。比如，打开一个 64MB 的文件，piece table 会有 1000 个节点。即使我们在每个节点中缓存了换行符位置，我们也不会知道哪一个绝对行是对应哪一个节点。 为了获取某一行的内容，我们需要从第一个节点开始遍历，直到找到该行。对于最坏的 case，这个时间复杂度是 O(n), n 表示的节点的数量。   

在每个 node 中缓存绝对的行数（第几行），并且在 list 上使用 二分查找法，可以加快查找速度。 但是，当我们修改一个节点时，必须要遍历后面所有的节点，进行行数更新。 这是不合适的，但是二分查找法的思路是对的。 为了能够达到同样的效果，我们可以使用平衡二叉树。    

我们现在必须决定使用什么 metadata 来作为比较树节点的关键。  



We now have to decide what metadata we should use as the key to compare tree nodes. As said, using the node's offset in the document or the absolute line number will bring the time complexity of editing operations to O(N). If we want a time complexity of O(log n), we need something that's only related to a tree node's subtree. Thus, when a user edits text, we recompute the metadata for the modified nodes, and then bubble the metadata change along the parent nodes all the way to the root.

If a Node has only four properties (bufferIndex, start, length, lineStarts), it takes seconds to find the result. To get faster, we can also store the text length and the line break count of a node's left subtree. This way searching by offset or line number from the root of the tree can be efficient. Storing metadata of the right subtree is the same but we don't need to cache both.

The classes now look like this:
```ts
class PieceTable {
  buffers: string[];
  rootNode: Node;
}

class Node {
  bufferIndex: number;
  start: number;
  length: number;
  lineStarts: number[];

  left_subtree_length: number;
  left_subtree_lfcnt: number;
  left: Node;
  right: Node;
  parent: Node;
}
```














